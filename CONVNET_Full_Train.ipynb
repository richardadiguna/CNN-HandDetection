{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CONVNET_Full_Train.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"N81bNPnrZDUs","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{"item_id":1}],"base_uri":"https://localhost:8080/","height":34},"outputId":"9078735e-a721-4d73-b5e8-2a32c5741ee1","executionInfo":{"status":"ok","timestamp":1518939962253,"user_tz":-420,"elapsed":785,"user":{"displayName":"Richard Adiguna","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"103732443883881279072"}}},"cell_type":"code","source":["import tensorflow as tf\n","tf.test.gpu_device_name()\n","\n","# !git clone https://github.com/richardadiguna/dataset.git\n","# !git clone https://gitlab.com/yehezkielrchad/saved_model.git\n","\n","# !cd saved_model/ && git status"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["''"]},"metadata":{"tags":[]},"execution_count":4}]},{"metadata":{"id":"nWL9jfxpZEaU","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{"item_id":7}],"base_uri":"https://localhost:8080/","height":326},"outputId":"122f01fa-a374-4436-8fe4-5c488ccdac89","executionInfo":{"status":"ok","timestamp":1518719553198,"user_tz":-420,"elapsed":13144,"user":{"displayName":"Richard Adiguna","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"103732443883881279072"}}},"cell_type":"code","source":["# Upgrade the tensorflow library\n","!pip install --upgrade tensorflow\n","\n","# Install matplotlib\n","!apt-get -qq install -y libfluidsynth1\n","\n","# Install openCV\n","!apt-get -qq install -y libsm6 libxext6 && pip install -q -U opencv-python\n","\n","# Install Scikit-learn\n","!pip install -U scikit-learn"],"execution_count":104,"outputs":[{"output_type":"stream","text":["Requirement already up-to-date: tensorflow in /usr/local/lib/python3.6/dist-packages\n","Requirement already up-to-date: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow)\n","Requirement already up-to-date: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow)\n","Requirement already up-to-date: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow)\n","Requirement already up-to-date: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow)\n","Requirement already up-to-date: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow)\n","Requirement already up-to-date: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow)\n","Requirement already up-to-date: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow)\n","Requirement already up-to-date: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow)\n","Requirement already up-to-date: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow)\n","Requirement already up-to-date: tensorboard<1.7.0,>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow)\n","Requirement already up-to-date: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.4.0->tensorflow)\n","Requirement already up-to-date: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.7.0,>=1.6.0->tensorflow)\n","Requirement already up-to-date: html5lib==0.9999999 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.7.0,>=1.6.0->tensorflow)\n","Requirement already up-to-date: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.7.0,>=1.6.0->tensorflow)\n","Requirement already up-to-date: bleach==1.5.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.7.0,>=1.6.0->tensorflow)\n","Requirement already up-to-date: scikit-learn in /usr/local/lib/python3.6/dist-packages\n"],"name":"stdout"}]},{"metadata":{"id":"ZWhSbNxIZGA8","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["%reload_ext autoreload\n","%autoreload 2\n","%matplotlib inline"],"execution_count":0,"outputs":[]},{"metadata":{"id":"EQbxATlQZHhD","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["import cv2\n","import tensorflow as tf\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import math\n","import csv\n","import os\n","import os.path\n","import random\n","from sklearn.model_selection import KFold, cross_val_score"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Q6OUxDByZJSM","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def load_hand_dataset():\n","    listdir = os.listdir('/home/adiguna/Downloads/hand_dataset/training_dataset/training_data/cropt-images/')\n","    listdir.sort()\n","    counter = 1\n","    for filename in listdir:\n","        image_read = cv2.imread('/home/adiguna/Downloads/hand_dataset/training_dataset/training_data/cropt-images/' + filename)\n","        image_resize = cv2.resize(image_read, (72, 72))\n","        cv2.imwrite('/home/adiguna/Downloads/hand_dataset/training_dataset/training_data/test_resize_image_72x72/training_hand_image_' + str(counter) + '.jpg', image_resize)\n","        counter += 1\n","\n","\n","def load_train_data(volume):\n","    imagesPath = []\n","    labels = []\n","    for i in range(0, volume):\n","        imageFile = 'dataset/training-dataset-32x32-normal/training-data-' + str(i) + '.jpg'\n","        label = 1\n","        imagesPath.append(imageFile)\n","        labels.append(label)\n","    for i in range(0, volume):\n","        imageFile = 'dataset/training-dataset-zero-32x32-normal/training-data-zero-' + str(i) + '.jpg'\n","        label = 0\n","        imagesPath.append(imageFile)\n","        labels.append(label)\n","    return imagesPath, labels\n","\n","\n","def load_test_data(volume):\n","    imagesPath = []\n","    labels = []\n","    for i in range(0, volume):\n","        imageFile = 'dataset/test-dataset-32x32-normal/test-data-' + str(i) + '.jpg'\n","        label = 1\n","        imagesPath.append(imageFile)\n","        labels.append(label)\n","    return imagesPath, labels"],"execution_count":0,"outputs":[]},{"metadata":{"id":"PyAieldtZLxd","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def generate_random_data(images, labels, rand_index):\n","    image_array = []\n","    label_array = []\n","    for i in range(len(rand_index)):\n","        index = rand_index[i]\n","        image = images[index]\n","        label = labels[index]\n","        image_array.append(image)\n","        label_array.append(label)\n","    return image_array, label_array\n","\n","\n","def reformat(images, labels):\n","    image_array = []\n","    label_array = []\n","    for i in range(len(images)):\n","        image = cv2.imread(images[i])\n","        image_array.append(image)\n","        label = (np.arange(num_labels) == labels[i]).astype(np.float32).tolist()\n","#         label = labels[i]\n","        label_array.append(label)\n","    return image_array, label_array"],"execution_count":0,"outputs":[]},{"metadata":{"id":"_xDkXrPEZPny","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def convolution2D(x, W):\n","    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n","\n","\n","def reluFunction(x):\n","    return tf.nn.relu(x)\n","\n","\n","def max_pool_3x3(x):\n","    return tf.nn.max_pool(x, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='SAME')\n","\n","\n","def local_response_normalization(conv, depth_radius, bias, alpha, beta, name):\n","    return tf.nn.lrn(conv, depth_radius, bias=bias, alpha=alpha / 9.0, beta=beta,\n","                     name=name)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Xv-fGwYaZR14","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Input Variable\n","x_input = tf.placeholder(dtype=tf.float32, shape=None)\n","y_target = tf.placeholder(dtype=tf.float32, shape=None)\n","val_input = tf.placeholder(dtype=tf.float32, shape=None)\n","val_target = tf.placeholder(dtype=tf.float32, shape=None)\n","eval_input = tf.placeholder(dtype=tf.float32, shape=None)\n","eval_target = tf.placeholder(dtype=tf.float32, shape=None)\n","keep_prob = tf.placeholder(dtype=tf.float32, shape=None)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"nQ-HK3VkZgf4","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["convolutional_1_output = 64\n","W_convolutional_1 = tf.Variable(tf.truncated_normal([5, 5, 3, convolutional_1_output], stddev=5e-2), name='W_convolutional_1')\n","b_convolutional_1 = tf.Variable(tf.zeros([convolutional_1_output]), name='b_convolutional_1')\n","convolutional_2_output = 64\n","W_convolutional_2 = tf.Variable(tf.truncated_normal([5, 5, convolutional_1_output, convolutional_2_output], stddev=5e-2), name='W_convolutional_2')\n","b_convolutional_2 = tf.Variable(tf.zeros([convolutional_2_output]), name='b_convolutional_2')\n","denseOutput1 = 384\n","denseInput1 = convolutional_2_output\n","W_dense_1 = tf.Variable(tf.truncated_normal(shape=[8 * 8 * denseInput1, denseOutput1], stddev=0.05), name='W_dense_1')\n","b_dense_1 = tf.Variable(tf.zeros([denseOutput1]), name='b_dense_1')\n","denseOutput2 = 192\n","denseInput2 = denseOutput1\n","W_dense_2 = tf.Variable(tf.truncated_normal(shape=[denseInput2, denseOutput2], stddev=0.05), name='W_dense_2')\n","b_dense_2 = tf.Variable(tf.zeros([denseOutput2]), name='b_dense_2')\n","denseOutput3 = 2\n","denseInput3 = denseOutput2\n","W_dense_3 = tf.Variable(tf.truncated_normal(shape=[denseInput3, denseOutput3], stddev=0.05), name='W_dense_3')\n","b_dense_3 = tf.Variable(tf.zeros([denseOutput3]), name='b_dense_3')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"BVTu2KaJZjgB","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def fullyconnected_layer(convResult):\n","    finalConvShape = convResult.get_shape().as_list()\n","    finalShape = finalConvShape[1] * finalConvShape[2] * finalConvShape[3]\n","    flatConvResult = tf.reshape(convResult, shape=[-1, finalShape])\n","    dense_1 = tf.matmul(flatConvResult, W_dense_1) + b_dense_1\n","    relu_dense_1 = reluFunction(dense_1)\n","    dense_2 = tf.matmul(relu_dense_1, W_dense_2) + b_dense_2\n","    relu_dense_2 = reluFunction(dense_2)\n","    logits = tf.matmul(relu_dense_2, W_dense_3) + b_dense_3\n","    return logits"],"execution_count":0,"outputs":[]},{"metadata":{"id":"3GP7ZVGvZmMT","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def convolution_network(left):\n","#   with tf.device('/gpu:0'):\n","  x = tf.reshape(left, shape=[-1, 32, 32, 3])\n","  convolution_1 = convolution2D(x, W_convolutional_1) + b_convolutional_1\n","  relu_convolution_1 = reluFunction(convolution_1)\n","  maxpool_convolution_1 = max_pool_3x3(relu_convolution_1)\n","  norm1 = local_response_normalization(maxpool_convolution_1, depth_radius=5, bias=1.0, alpha=0.001, beta=0.75, name='norm1')\n","  convolution_2 = convolution2D(norm1, W_convolutional_2) + b_convolutional_2\n","  relu_convolution_2 = reluFunction(convolution_2)\n","  norm2 = local_response_normalization(relu_convolution_2, depth_radius=5, bias=1.0, alpha=0.001, beta=0.75, name='norm2')\n","  maxpool_convolution_2 = max_pool_3x3(norm2)\n","  dense = fullyconnected_layer(maxpool_convolution_2)\n","  return dense"],"execution_count":0,"outputs":[]},{"metadata":{"id":"C_2KVwp5ZX44","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Hyperparameter\n","learning_rate = 0.00001\n","batch_size = 32  # numbers of batch size must be declare during training process\n","steps = 125  # numbers of iteration must be declare during training process\n","epochs = 40  # numbers epochs must be declare during training process\n","num_labels = 2"],"execution_count":0,"outputs":[]},{"metadata":{"id":"jOhXezXhZv5K","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["global_step = tf.Variable(0, trainable=False, name='global_step', dtype= tf.int32)\n","learning_rate_decay_factor = 0.96 \n","num_epochs_per_decay = 12\n","num_examples_per_epochs = 4000\n","num_batches_per_epoch = int(num_examples_per_epochs / batch_size)\n","decay_steps = int(num_batches_per_epoch * num_epochs_per_decay)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"xSgfykR7Z6d8","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["model_learning_rate = tf.train.exponential_decay(learning_rate, global_step, decay_steps, learning_rate_decay_factor, staircase=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ngZqzKSfZ65f","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# L2 Normalization\n","beta = 0.04\n","regulizers_W_dense_1 = tf.nn.l2_loss(W_dense_1)\n","regulizers_W_dense_2 = tf.nn.l2_loss(W_dense_2)\n","regulizers = regulizers_W_dense_1 + regulizers_W_dense_2"],"execution_count":0,"outputs":[]},{"metadata":{"id":"vZfdKUiQaAMd","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Define loss and optimizer\n","model_output = convolution_network(x_input)\n","validation_model_output = convolution_network(val_input)\n","test_model_output = convolution_network(eval_input)  # For evaluate the model\n","\n","cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=model_output, labels=y_target))\n","regulizers = regulizers_W_dense_1 + regulizers_W_dense_2\n","cost = tf.reduce_mean(cost + beta * regulizers)\n","optimizer = tf.train.GradientDescentOptimizer(learning_rate=model_learning_rate)\n","train_op = optimizer.minimize(loss=cost, global_step=global_step)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"heO72X6NaEAB","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Prediction using softmax\n","prediction = tf.nn.softmax(model_output)\n","validation_prediction = tf.nn.softmax(validation_model_output)\n","test_prediction = tf.nn.softmax(test_model_output)  # For evaluate the model"],"execution_count":0,"outputs":[]},{"metadata":{"id":"wQqPpHlSaGBV","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Get Model Accuracy\n","correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(y_target, 0))\n","accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"6afv9IqxaIiv","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Test accuracy model\n","def accuracy_of_batch(predictions, labels):\n","    targets = tf.squeeze(tf.cast(labels, tf.int32))\n","    targets_argmax = tf.cast(tf.argmax(targets, 1), tf.int32)\n","    bacth_predictions = tf.cast(tf.argmax(predictions, 1), tf.int32)\n","    predicted_correctly = tf.equal(bacth_predictions, targets_argmax)\n","    # print(sess.run(targets_argmax))\n","    # print(sess.run(bacth_predictions))\n","    # print(sess.run(predicted_correctly))\n","    accuracy = tf.reduce_mean(tf.cast(predicted_correctly, tf.float32)) * 100\n","    return accuracy\n","  \n","def accuracy_batch_sparse(predictions, labels):\n","  batch_prediction = tf.cast(tf.argmax(predictions, 1), tf.int32)\n","  predicted_correctly = tf.equal(batch_prediction, labels)\n","  accuracy = tf.reduce_mean(tf.cast(predicted_correctly, tf.float32))\n","  return accuracy"],"execution_count":0,"outputs":[]},{"metadata":{"id":"eojwg_S4aOg6","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def k_fold(a, n_split):\n","    trainFolds = []\n","    validationFolds = []\n","    kf = KFold(n_splits=n_split)\n","    a = kf.split(a)\n","    for train_index, test_index in a:\n","        trainFolds.append(train_index)\n","        validationFolds.append(test_index)\n","    return trainFolds, validationFolds\n","\n","def get_fold_data(data, index_array):\n","    result = []\n","    for index in index_array:\n","        result.append(data[index])\n","    return result"],"execution_count":0,"outputs":[]},{"metadata":{"id":"yoergisOaRWd","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["init = tf.global_variables_initializer()\n","saver = tf.train.Saver()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"VcJ1IpeCaWue","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["train_images, train_labels = load_train_data(2000)\n","train_images, train_labels = reformat(train_images, train_labels)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"PNtQbg7zaYZa","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["config = tf.ConfigProto()\n","config.gpu_options.allow_growth = True\n","\n","sess = tf.InteractiveSession()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"rPbTsONUaemV","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Validation accuracy\n","validation_accuracy = []\n","# Test Variable\n","test_pred = []\n","test_error = []\n","test_acc = []\n","# Train Variable\n","train_cost = []\n","train_cost_per_batch = []\n","train_acc = []\n","train_acc_per_batch = []\n","# Validation Variable\n","validation_pred = []\n","validation_error = []\n","validation_acc = []\n","validationTotalError = 0\n","# Validation per fold Variable\n","val_error_per_fold = []\n","val_pred_per_fold = []\n","val_total_error_per_fold = 0\n","# Batch Variable\n","numbers_of_cost_per_batch = 0\n","numbers_of_acc_per_batch = 0\n","sess.run(init)\n","index_distribution = len(train_images)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"D8xFbKu4afr7","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["for i in range(0, epochs):\n","  train_cost_per_batch.clear()\n","  train_acc_per_batch.clear()\n","  for j in range(0, steps):\n","      rand_index = np.random.choice(index_distribution, size=batch_size)\n","      rand_train_images, rand_train_labels = generate_random_data(train_images, train_labels, rand_index)\n","      train = sess.run(train_op, feed_dict={x_input: rand_train_images, y_target: rand_train_labels})\n","      temp_train_pred = sess.run(prediction, feed_dict={x_input: rand_train_images})\n","      temp_train_cost = sess.run(cost, feed_dict={x_input: rand_train_images, y_target: rand_train_labels})\n","      temp_train_acc = sess.run(accuracy_of_batch(temp_train_pred, rand_train_labels))\n","      train_cost_per_batch.append(temp_train_cost)\n","      train_acc_per_batch.append(temp_train_acc)\n","      numbers_of_cost_per_batch += 1\n","      numbers_of_acc_per_batch += 1\n","      print(\"Training Validation hand image on epoch: \" + str(i) + \", on step: \" + str(j) + ', loss: ' + str(temp_train_cost) + ', acc: ' + str(temp_train_acc))\n","      if math.isnan(temp_train_cost):\n","          print('Loss is nan')\n","  accuracy_result_per_epochs = tf.reduce_mean(train_acc_per_batch)\n","  delta_cost_per_epochs = tf.reduce_mean(train_cost_per_batch)\n","  train_acc.append(accuracy_result_per_epochs)\n","  train_cost.append(delta_cost_per_epochs)\n","  print('delta_cost_per_epochs:' + str(sess.run(delta_cost_per_epochs)))\n","  print('accuracy_result_per_epochs: ' + str(sess.run(accuracy_result_per_epochs)))\n","  print('Learning rate: ', sess.run(model_learning_rate))\n","  if i % 5 == 0:\n","      print('Saving model......  ')\n","accuracyResult = (tf.reduce_mean(train_acc))\n","costResult = (tf.reduce_mean(train_cost))\n","print('total accuracy: ' + str(sess.run(accuracyResult)))\n","print('final cost: ' + str(sess.run(costResult)))\n","# save_path = saver.save(sess,'/saved_model/CUDA/fold_' + str(fold) + '/model_fold_' + str(fold) + '.ckpt')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"f5JPCjynaic1","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["test_images, test_labels = load_test_data(240)\n","test_images, test_labels = reformat(test_images, test_labels)\n","for i in range(0, len(test_images)):\n","  print('Test Model on test_image ' + str(i))\n","  test_image = test_images[i]\n","  test_label = [test_labels[i]]\n","  test_predict = sess.run(test_prediction, feed_dict={eval_input: test_image, keep_prob: 1.0})\n","  print(test_predict)\n","  error = sess.run(cost, feed_dict={x_input: test_images[i], y_target: test_label, keep_prob: 1.0})\n","  print(error)\n","  test_error.append(error)\n","  correct_pred_result = sess.run(correct_pred, feed_dict={prediction: test_predict, y_target: test_labels[i]})\n","  correct_pred_result = tf.cast(correct_pred_result, tf.float32)\n","  test_pred.append(correct_pred_result)\n","avg_error = tf.reduce_mean(test_error)\n","test_accuracy = tf.reduce_mean(tf.cast(test_pred, tf.float32))\n","print('Test Error Rate:', sess.run(avg_error))\n","print('Test Accuracy Result:', sess.run(test_accuracy))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"pG5UQThKa9jh","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["sess.close()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Imi7ZFHLbfJD","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["!ls && cd saved_model/ && mkdir ZFNET && mkdir CUDA && cd ZFNET/ && mkdir fold_0"],"execution_count":0,"outputs":[]}]}